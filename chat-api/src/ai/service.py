"""
ğŸ¤– AI æœåŠ¡

æä¾›ç»Ÿä¸€çš„AIæœåŠ¡æ¥å£
"""

import asyncio
from typing import Dict, List, Optional, Any, AsyncGenerator

from loguru import logger

from src.config.settings import get_settings
from src.core.exceptions import AIServiceException
from src.ai.client import get_dashscope_client, get_openai_client

settings = get_settings()


class AIService:
    """AIæœåŠ¡ç±»"""
    
    def __init__(self):
        self.default_provider = "dashscope"  # é»˜è®¤ä½¿ç”¨DashScope
        self.retry_attempts = settings.AI_RETRY_ATTEMPTS
        self.retry_delay = settings.AI_RETRY_DELAY
    
    async def send_message(
        self,
        messages: List[Dict[str, str]],
        provider: str = None,
        **kwargs
    ) -> str:
        """
        å‘é€æ¶ˆæ¯åˆ°AIæœåŠ¡
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}]
            provider: AIæœåŠ¡æä¾›å•† (dashscope/openai)
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            AIå›å¤å†…å®¹
        """
        provider = provider or self.default_provider
        
        for attempt in range(self.retry_attempts):
            try:
                if provider == "dashscope":
                    client = await get_dashscope_client()
                    if not client:
                        raise AIServiceException("DashScope client not available")
                    
                    return await client.send_message(messages, **kwargs)
                
                elif provider == "openai":
                    client = await get_openai_client()
                    if not client:
                        raise AIServiceException("OpenAI client not available")
                    
                    return await client.send_message(messages, **kwargs)
                
                else:
                    raise AIServiceException(f"Unknown AI provider: {provider}")
            
            except AIServiceException as e:
                if attempt == self.retry_attempts - 1:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æä¾›å•†
                    if provider == "dashscope":
                        logger.warning(f"DashScope failed, trying OpenAI: {e}")
                        try:
                            return await self.send_message(messages, "openai", **kwargs)
                        except Exception:
                            pass
                    elif provider == "openai":
                        logger.warning(f"OpenAI failed, trying DashScope: {e}")
                        try:
                            return await self.send_message(messages, "dashscope", **kwargs)
                        except Exception:
                            pass
                    
                    raise e
                
                logger.warning(f"AI request attempt {attempt + 1} failed: {e}")
                await asyncio.sleep(self.retry_delay * (attempt + 1))
        
        raise AIServiceException("All AI service attempts failed")
    
    async def stream_message(
        self,
        messages: List[Dict[str, str]],
        provider: str = None,
        **kwargs
    ) -> AsyncGenerator[str, None]:
        """
        æµå¼å‘é€æ¶ˆæ¯åˆ°AIæœåŠ¡
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            provider: AIæœåŠ¡æä¾›å•†
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            AIå›å¤å†…å®¹ç‰‡æ®µ
        """
        provider = provider or self.default_provider
        
        try:
            if provider == "dashscope":
                client = await get_dashscope_client()
                if not client:
                    raise AIServiceException("DashScope client not available")
                
                async for chunk in client.stream_message(messages, **kwargs):
                    yield chunk
            
            elif provider == "openai":
                client = await get_openai_client()
                if not client:
                    raise AIServiceException("OpenAI client not available")
                
                async for chunk in client.stream_message(messages, **kwargs):
                    yield chunk
            
            else:
                raise AIServiceException(f"Unknown AI provider: {provider}")
        
        except AIServiceException as e:
            # æµå¼è¯·æ±‚å¤±è´¥æ—¶å°è¯•å¤‡ç”¨æä¾›å•†
            if provider == "dashscope":
                logger.warning(f"DashScope stream failed, trying OpenAI: {e}")
                try:
                    async for chunk in self.stream_message(messages, "openai", **kwargs):
                        yield chunk
                    return
                except Exception:
                    pass
            elif provider == "openai":
                logger.warning(f"OpenAI stream failed, trying DashScope: {e}")
                try:
                    async for chunk in self.stream_message(messages, "dashscope", **kwargs):
                        yield chunk
                    return
                except Exception:
                    pass
            
            raise e
    
    async def chat_completion(
        self,
        user_message: str,
        conversation_history: List[Dict[str, str]] = None,
        system_prompt: str = None,
        **kwargs
    ) -> str:
        """
        èŠå¤©è¡¥å…¨
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            AIå›å¤
        """
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        # æ·»åŠ å¯¹è¯å†å²
        if conversation_history:
            messages.extend(conversation_history)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        return await self.send_message(messages, **kwargs)
    
    async def stream_chat_completion(
        self,
        user_message: str,
        conversation_history: List[Dict[str, str]] = None,
        system_prompt: str = None,
        **kwargs
    ) -> AsyncGenerator[str, None]:
        """
        æµå¼èŠå¤©è¡¥å…¨
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            AIå›å¤ç‰‡æ®µ
        """
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        # æ·»åŠ å¯¹è¯å†å²
        if conversation_history:
            messages.extend(conversation_history)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        async for chunk in self.stream_message(messages, **kwargs):
            yield chunk
    
    def build_conversation_context(
        self,
        messages: List[Dict[str, Any]],
        max_context_length: int = 4000
    ) -> List[Dict[str, str]]:
        """
        æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            max_context_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            
        Returns:
            æ ¼å¼åŒ–çš„å¯¹è¯ä¸Šä¸‹æ–‡
        """
        context = []
        total_length = 0
        
        # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹ï¼Œå‘å‰æ„å»ºä¸Šä¸‹æ–‡
        for message in reversed(messages):
            content = message.get("content", "")
            sender_type = message.get("sender_type", "")
            
            # è½¬æ¢å‘é€è€…ç±»å‹åˆ°AIæ ¼å¼
            if sender_type == "contact":
                role = "user"
            elif sender_type in ["agent", "ai"]:
                role = "assistant"
            else:
                continue  # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯ç­‰
            
            message_length = len(content)
            if total_length + message_length > max_context_length:
                break
            
            context.insert(0, {"role": role, "content": content})
            total_length += message_length
        
        return context
    
    def get_default_system_prompt(self, language: str = "zh-CN") -> str:
        """
        è·å–é»˜è®¤ç³»ç»Ÿæç¤ºè¯
        
        Args:
            language: è¯­è¨€ä»£ç 
            
        Returns:
            ç³»ç»Ÿæç¤ºè¯
        """
        prompts = {
            "zh-CN": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œè¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. å‹å¥½ã€è€å¿ƒã€ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·é—®é¢˜
2. å¦‚æœä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯šå®è¯´æ˜å¹¶å»ºè®®è”ç³»äººå·¥å®¢æœ
3. ä¿æŒå›ç­”ç®€æ´æ˜äº†ï¼Œé¿å…è¿‡äºå†—é•¿
4. ä¼˜å…ˆè§£å†³ç”¨æˆ·çš„å®é™…é—®é¢˜
5. å¦‚æœç”¨æˆ·è¦æ±‚è½¬äººå·¥å®¢æœï¼Œè¯·åŠæ—¶å“åº”""",
            
            "en-US": """You are a professional customer service assistant. Please follow these principles:
1. Answer user questions in a friendly, patient, and professional manner
2. If you're unsure about an answer, be honest and suggest contacting human support
3. Keep responses concise and clear, avoiding overly lengthy explanations
4. Prioritize solving users' actual problems
5. If users request human support, respond promptly""",
        }
        
        return prompts.get(language, prompts["zh-CN"])
    
    async def check_service_availability(self) -> Dict[str, bool]:
        """
        æ£€æŸ¥AIæœåŠ¡å¯ç”¨æ€§
        
        Returns:
            å„æœåŠ¡æä¾›å•†çš„å¯ç”¨æ€§çŠ¶æ€
        """
        availability = {}
        
        # æ£€æŸ¥DashScope
        try:
            client = await get_dashscope_client()
            if client:
                # å‘é€æµ‹è¯•æ¶ˆæ¯
                test_messages = [{"role": "user", "content": "Hello"}]
                await client.send_message(test_messages)
                availability["dashscope"] = True
            else:
                availability["dashscope"] = False
        except Exception as e:
            logger.warning(f"DashScope availability check failed: {e}")
            availability["dashscope"] = False
        
        # æ£€æŸ¥OpenAI
        try:
            client = await get_openai_client()
            if client:
                # å‘é€æµ‹è¯•æ¶ˆæ¯
                test_messages = [{"role": "user", "content": "Hello"}]
                await client.send_message(test_messages)
                availability["openai"] = True
            else:
                availability["openai"] = False
        except Exception as e:
            logger.warning(f"OpenAI availability check failed: {e}")
            availability["openai"] = False
        
        return availability


# å…¨å±€AIæœåŠ¡å®ä¾‹
ai_service = AIService()
